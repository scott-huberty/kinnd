{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "import mne\n",
    "\n",
    "import kinnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_SERVER_IS_MOUNTED = kinnd.utils.paths.lab_server_is_mounted(strict=False)\n",
    "LOCAL_DATA_DIR = Path(\"/Volumes\") / \"UBUNTU18\" / \"USC\" / \"charlotte_semantics_data\" / \"sem_esrp\"\n",
    "if LAB_SERVER_IS_MOUNTED:\n",
    "    directory = None\n",
    "else:\n",
    "    directory = LOCAL_DATA_DIR\n",
    "\n",
    "\n",
    "fpaths = kinnd.utils.paths.get_semantics_fpaths(directory=directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Subject List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_assignment(filename=None):\n",
    "    \"\"\"Return a DataFrame containing the group assignment for each semantics subject.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str | Path | None\n",
    "        If None, will attempt to load the file from the lab server at\n",
    "        ``charlotte_semantics_data/ERSP_Particpants.xlsx.``. If a str or Path, it must\n",
    "        point tot he file that contains the group assignment for each subject in the\n",
    "        semantics study. This file is named ``ERSP_Particpants.xlsx`` on the lab server.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        A DataFrame with the following columns:\n",
    "        - subject : str\n",
    "            The subject ID.\n",
    "        - group : str\n",
    "            The group assignment for the subject.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        fname = kinnd.utils.paths.lab_server_path() / \"charlotte_semantics_data\" / \"ERSP_Particpants.xlsx\"\n",
    "    else:\n",
    "        if not isinstance(directory, (str, Path)):\n",
    "            raise TypeError(f\"filename must be a str or Path. Got {type(filename)}\")\n",
    "        fname = Path(filename).expanduser().resolve()\n",
    "        if not fname.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {fname}\")\n",
    "    participants_df = pd.read_excel(fname)\n",
    "\n",
    "    mv_asd_series = participants_df[\"MV ASD\"].to_frame(name=\"subject\").dropna()\n",
    "    mv_asd_series[\"group\"] = \"ASD-Nonverbal\"\n",
    "\n",
    "    v_asd_series = participants_df[\"V ASD\"].to_frame(name=\"subject\").dropna()\n",
    "    v_asd_series[\"group\"] = \"ASD-Verbal\"\n",
    "\n",
    "    td_series = participants_df[\"TD\"].to_frame(name=\"subject\").dropna()\n",
    "    td_series[\"group\"] = \"TD\"\n",
    "\n",
    "    df = pd.concat([mv_asd_series, v_asd_series, td_series], ignore_index=True)\n",
    "    for tup in df.itertuples():\n",
    "        stem = \"sub-\"\n",
    "        sub = tup.subject.replace(\"s17\", \"\")\n",
    "        sub = str(int(sub)).zfill(2)\n",
    "        df.loc[tup.Index, \"subject\"] = stem + sub\n",
    "    df = df.drop(index=df[df.subject == \"sub-23\"].index)\n",
    "    df.set_index(\"subject\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_group_assignment(filename=LOCAL_DATA_DIR.parent / \"ERSP_Participants.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "semantics_epochs = defaultdict()\n",
    "for subject in tqdm(fpaths, total=len(fpaths)):\n",
    "    ep = kinnd.studies.semantics.read_epochs_semantics(fpaths, subject, verbose=\"CRITICAL\")\n",
    "    semantics_epochs[subject] = ep\n",
    "semantics_epochs = dict(semantics_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_to_xarray(ep):\n",
    "    \"\"\"Convert an MNE Epochs object to an xarray Dataset.\"\"\"\n",
    "    cond_xrs = defaultdict()\n",
    "    for condition in ep.event_id:\n",
    "        if not len(ep[condition]):\n",
    "            continue\n",
    "        data = ep[condition].get_data()\n",
    "        dims = (\"epoch\", \"channel\", \"time\")\n",
    "        coords = {\n",
    "            \"epoch\": ep[condition].selection,\n",
    "            \"channel\": ep.ch_names,\n",
    "            \"time\": ep.times,\n",
    "        }\n",
    "        cond_xrs[condition] = xr.DataArray(data, coords=coords, dims=dims)\n",
    "    return xr.Dataset(cond_xrs)\n",
    "\n",
    "semantics_xr = {subject: epochs_to_xarray(ep)\n",
    "                for subject, ep\n",
    "                in tqdm(semantics_epochs.items())\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LAB_SERVER_IS_MOUNTED:\n",
    "    out_dir = kinnd.utils.paths.semantics_path() / \"derivatives\" / \"epochs\"\n",
    "    assert out_dir.exists()\n",
    "\n",
    "    for subject, xr_data in tqdm(semantics_xr.items(), total=len(semantics_xr)):\n",
    "        out_fpath = out_dir / f\"{subject}_epochs.netcdf\"\n",
    "        xr_data.to_netcdf(out_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantics_evoked_xr = defaultdict()\n",
    "\n",
    "for subject, ep in semantics_epochs.items():\n",
    "    condition_xrs = defaultdict()\n",
    "    for condition in [\"match\", \"mismatch\"]:\n",
    "        ev = ep[condition].apply_baseline((None, 0)).average()\n",
    "        assert ev.data.shape == (len(ev.ch_names), len(ev.times))\n",
    "\n",
    "        ev_xr = xr.DataArray(\n",
    "            [ev.data],\n",
    "            coords={\n",
    "                \"subject\": [subject],\n",
    "                \"channel\": ev.ch_names,\n",
    "                \"time\": ev.times,\n",
    "            },\n",
    "            dims=(\"subject\", \"channel\", \"time\"),\n",
    "        )\n",
    "        condition_xrs[condition] = ev_xr\n",
    "    ev_ds = xr.Dataset(condition_xrs)\n",
    "    semantics_evoked_xr[subject] = ev_ds\n",
    "semantics_evoked_xr = dict(semantics_evoked_xr)\n",
    "\n",
    "semantics_evoked_xr = xr.concat(semantics_evoked_xr.values(), dim=\"subject\")\n",
    "if LAB_SERVER_IS_MOUNTED:\n",
    "    semantics_evoked_xr.to_netcdf(out_dir.parent / \"evoked\" / \"evoked.netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantics_evoked_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "ds = semantics_evoked_xr\n",
    "ROI = [\"Cz\", \"Fz\"]\n",
    "ds_long = ds[[\"match\", \"mismatch\"]].sel(channel=ROI, time=slice(1.0, None)).mean(\"channel\").to_dataframe().reset_index().melt(\n",
    "    id_vars=[\"subject\", \"time\"],\n",
    "    value_vars=[\"match\", \"mismatch\"],\n",
    "    var_name=\"condition\",\n",
    "    value_name=\"amplitude\"\n",
    ")\n",
    "ds_long = ds_long.set_index(\"subject\").join(df)\n",
    "\n",
    "sns.lineplot(data=ds_long.loc[ds_long.group == \"TD\"],\n",
    "             x=\"time\",\n",
    "             y=\"amplitude\",\n",
    "             hue=\"condition\",\n",
    "             errorbar=\"sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinnd.viz.plot_topomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kinnd.viz\n",
    "\n",
    "\n",
    "mon = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "info = mne.create_info(\n",
    "    ch_names=ds[\"match\"].channel.values.tolist(),\n",
    "    sfreq=1000,\n",
    "    ch_types=\"eeg\",\n",
    ")\n",
    "info.set_montage(mon)\n",
    "\n",
    "def get_difference_wave(ds):\n",
    "    \"\"\"Subtract the match from the mismatch waveform for each subject.\"\"\"\n",
    "    match = ds[\"match\"].sel(time=slice(1.0, None)).mean([\"subject\", \"time\"])\n",
    "    mismatch = ds[\"mismatch\"].sel(time=slice(1.0, None)).mean([\"subject\", \"time\"])\n",
    "    diff = mismatch - match\n",
    "    return diff\n",
    "sel_kwargs = dict(time=slice(1.0, None))\n",
    "diff_td = get_difference_wave(\n",
    "    ds.sel(subject=df[df.group == \"TD\"].index, **sel_kwargs)\n",
    "    )\n",
    "diff_asd_v = get_difference_wave(\n",
    "    ds.sel(subject=df[df.group == \"ASD-Verbal\"].index, **sel_kwargs)\n",
    "    )\n",
    "diff_asd_mv = get_difference_wave(\n",
    "    ds.sel(subject=df[df.group == \"ASD-Nonverbal\"].index, **sel_kwargs)\n",
    "    )\n",
    "\n",
    "vmin = np.min([diff_td.values, diff_asd_v.values, diff_asd_mv.values])\n",
    "vmax = np.max([diff_td.values, diff_asd_v.values, diff_asd_mv.values])\n",
    "assert isinstance(vmin, (int, float))\n",
    "assert isinstance(vmax, (int, float))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, constrained_layout=True, figsize=(10, 5))\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "topo_kwargs = dict(show=False, vlim=(vmin, vmax), names=diff_td.channel.values)\n",
    "\n",
    "dat = dict(zip(diff_td.channel.values, diff_td.values))\n",
    "kinnd.viz.plot_topomap(\n",
    "    dat, info, axes=ax[0], **topo_kwargs)\n",
    "ax[0].set_title(\"TD\")\n",
    "\n",
    "dat = dict(zip(diff_asd_v.channel.values, diff_asd_v.values))\n",
    "kinnd.viz.plot_topomap(dat, info, axes=ax[1], **topo_kwargs)\n",
    "ax[1].set_title(\"ASD-Verbal\")\n",
    "\n",
    "dat = dict(zip(diff_asd_mv.channel.values, diff_asd_mv.values))\n",
    "kinnd.viz.plot_topomap(dat, info, axes=ax[2], **topo_kwargs)\n",
    "ax[2].set_title(\"ASD-Nonverbal\")\n",
    "\n",
    "fig.suptitle(\"Mismatch - Match EEG activity (1-2s)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "groups = df.group.unique()\n",
    "assert len(groups) == 3\n",
    "conditions = [\"match\", \"mismatch\"]\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "group_dict = defaultdict()\n",
    "for group, condition in itertools.product(groups, conditions):\n",
    "    data = (ds[condition].sel(subject=df[df.group == group].index, **sel_kwargs)\n",
    "                         .mean([\"subject\", \"time\"])\n",
    "                         )\n",
    "    group_dict[(group, condition)] = dict(zip(data.channel.values, data.values))\n",
    "\n",
    "vmin = np.min(\n",
    "    [list(group_dict[(group, condition)].values())\n",
    "     for group in groups\n",
    "     for condition in conditions\n",
    "     ]\n",
    "    )\n",
    "vmax = np.max(\n",
    "    [list(group_dict[(group, condition)].values())\n",
    "     for group in groups\n",
    "     for condition in conditions\n",
    "     ]\n",
    "    )\n",
    "assert isinstance(vmin, (int, float))\n",
    "assert isinstance(vmax, (int, float))\n",
    "vlim = (vmin, vmax)\n",
    "topo_kwargs = dict(show=False, vlim=vlim, names=data.channel.values)\n",
    "\n",
    "for this_ax, (group, condition) in zip(axes.flatten(), list(itertools.product(groups, conditions))):\n",
    "    data = (ds[condition].sel(subject=df[df.group == group].index, **sel_kwargs)\n",
    "                         .mean([\"subject\", \"time\"])\n",
    "                         )\n",
    "    data_dict = dict(zip(data.channel.values, data.values))\n",
    "    kinnd.viz.plot_topomap(\n",
    "        data_dict,\n",
    "        info,\n",
    "        axes=this_ax,\n",
    "        **topo_kwargs,\n",
    "    )\n",
    "    this_ax.set_title(f\"{group}: {condition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRONT = [\"F3\", \"Fz\", \"F4\"]\n",
    "MID = [\"C3\", \"Cz\", \"C4\"]\n",
    "ROI = FRONT + MID\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, constrained_layout=True, figsize=(10, 5))\n",
    "sns.set_style(\"darkgrid\")\n",
    "colors = sns.color_palette()\n",
    "melt_kwargs = dict(id_vars=[\"subject\", \"time\"],\n",
    "                    value_vars=[\"match\", \"mismatch\"],\n",
    "                    var_name=\"condition\", value_name=\"amplitude\"\n",
    "                    )\n",
    "\n",
    "for this_ax, this_group in zip(axes, (\"TD\", \"ASD-Verbal\", \"ASD-Nonverbal\")):\n",
    "    df_ev = ds.sel(subject=df[df.group == this_group].index, channel=ROI).mean(\"channel\").to_dataframe()\n",
    "    df_ev = df_ev.reset_index().melt(**melt_kwargs)\n",
    "    sns.lineplot(data=df_ev, x=\"time\", y=\"amplitude\", hue=\"condition\", ax=this_ax)\n",
    "    this_ax.set_ylim(-1.4*1e-5, .4*1e-5) # rough guess based on the data\n",
    "    this_ax.set_title(f\"{this_group}: Frontal ROI\")\n",
    "    this_ax.axvline(1.0, color=\"k\", linestyle=\"--\")\n",
    "    this_ax.axvspan(0.0, 0.99, color=colors[2], alpha=0.1)\n",
    "    this_ax.axvspan(1.0, 2.0, color=colors[4], alpha=0.2)\n",
    "    this_ax.text(0.5, 0, \"Image\", ha=\"center\", va=\"center\", fontsize=12)\n",
    "    this_ax.text(1.5, -1.0*1e-5, \"Word\", ha=\"center\", va=\"center\", fontsize=12)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_band_col(df):\n",
    "    \"\"\"Add a column to a DataFrame that indicates the frequency band of each row.\"\"\"\n",
    "    freq_bounds = {\"_\": 0, \"delta\": 3, \"theta\": 7, \"alpha\": 13, \"beta\": 30, \"gamma\": 50}\n",
    "    df[\"band\"] = pd.cut(\n",
    "        df[\"freq\"], bins=list(freq_bounds.values()),\n",
    "        labels=list(freq_bounds.keys())[1:]\n",
    "    )\n",
    "    freq_bands_of_interest = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "    df = df[df.band.isin(freq_bands_of_interest)]\n",
    "    df[\"band\"] = df[\"band\"].cat.remove_unused_categories()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_dict = defaultdict()\n",
    "for subject, ep in semantics_epochs.items():\n",
    "    psd = ep.copy().apply_baseline((None, 0)).crop(tmin=1.0, tmax=2.0)\n",
    "    psd = psd.compute_psd(method=\"welch\", fmin=2, fmax=50)\n",
    "    pow_xrs = defaultdict()\n",
    "    for condition in psd.event_id:\n",
    "        if not len(psd[condition]):\n",
    "            continue\n",
    "        assert psd.average().data.shape == (len(psd.ch_names), len(psd.freqs))\n",
    "        pow_xr = xr.DataArray(\n",
    "            [psd[condition].average().data],\n",
    "            coords={\n",
    "                \"subject\": [subject],\n",
    "                \"channel\": psd.ch_names,\n",
    "                \"freq\": psd.freqs,\n",
    "            },\n",
    "            dims=(\"subject\", \"channel\", \"freq\"),\n",
    "        )\n",
    "        pow_xrs[condition] = pow_xr\n",
    "    power_dict[subject] = xr.Dataset(pow_xrs)\n",
    "power_dict = dict(power_dict)\n",
    "power_ds = xr.concat(power_dict.values(), dim=\"subject\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vlim(group_dict):\n",
    "   \"\"\"Get the vmin and vmax for the topomaps.\"\"\"\n",
    "   vmin = np.min([list(group_dict[(group, condition)].values())\n",
    "                  for group in groups\n",
    "                  for condition in conditions\n",
    "                  ])\n",
    "   vmax = np.max([list(group_dict[(group, condition)].values())\n",
    "                  for group in groups\n",
    "                  for condition in conditions\n",
    "                  ])\n",
    "   assert isinstance(vmin, (int, float))\n",
    "   assert isinstance(vmax, (int, float))\n",
    "   return (vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power(power_ds, *, group_df, group, condition, freqs):\n",
    "    \"\"\"Get the power for a group and condition.\"\"\"\n",
    "    df = group_df\n",
    "    data = (power_ds[condition].sel(subject=df[df.group == group].index, freq=freqs).sum(\"freq\")\n",
    "                              .mean(\"subject\")\n",
    "                              )\n",
    "    return dict(zip(data.channel.values, data.values))\n",
    "\n",
    "freq_bands = {\"delta\": slice(2, 4),\n",
    "              \"theta\": slice(4, 8),\n",
    "              \"alpha\": slice(8, 13),\n",
    "              \"beta\": slice(13, 30),\n",
    "              \"gamma\": slice(30, 50)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_power(power_ds,\n",
    "          group_df=df,\n",
    "          group=\"TD\",\n",
    "          condition=\"match\",\n",
    "          freqs=freq_bands[\"delta\"]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_power_topomaps(power_ds, *, group_df, band):\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(10, 10), constrained_layout=True)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    groups = group_df.group.unique()\n",
    "    conditions = power_ds.data_vars\n",
    "\n",
    "    group_power_dict = defaultdict()\n",
    "    vmins = []\n",
    "    vmaxs = []\n",
    "    BAND = band.lower()\n",
    "    for this_group, this_condition, in list(itertools.product(groups, conditions)):\n",
    "        this_power = get_power(\n",
    "            power_ds,\n",
    "            group_df=group_df,\n",
    "            group=this_group,\n",
    "            condition=this_condition,\n",
    "            freqs=freq_bands[BAND]\n",
    "            )\n",
    "        vmins.append(np.min(list(this_power.values())))\n",
    "        vmaxs.append(np.max(list(this_power.values())))\n",
    "        group_power_dict[(this_group, this_condition)] = this_power\n",
    "\n",
    "    vlim = (np.min(vmins), np.max(vmaxs))\n",
    "    topo_kwargs = dict(show=False, vlim=vlim, names=list(this_power.keys()))\n",
    "\n",
    "    for this_ax, (group, condition) in zip(ax.flatten(), list(itertools.product(groups, conditions))):\n",
    "        data = group_power_dict[(group, condition)]\n",
    "        kinnd.viz.plot_topomap(\n",
    "            data,\n",
    "            info,\n",
    "            axes=this_ax,\n",
    "            **topo_kwargs,\n",
    "        )\n",
    "        this_ax.set_title(f\"{group}: {condition}\")\n",
    "    fig.suptitle(f\"{BAND.capitalize()} power (1-2s)\")\n",
    "\n",
    "plot_power_topomaps(power_ds, group_df=df, band=\"delta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds, group_df=df, band=\"theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds, group_df=df, band=\"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds, group_df=df, band=\"beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds, group_df=df, band=\"gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psds(power_ds, *, group_df, log=True, vlim=None):\n",
    "    \"\"\"Plot the power spectral density for each group.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, constrained_layout=True, figsize=(10, 5))\n",
    "    sns.set_style(\"darkgrid\")\n",
    "\n",
    "    groups = group_df.group.unique()\n",
    "    conditions = power_ds.data_vars\n",
    "\n",
    "    melt_kwargs = dict(\n",
    "        id_vars=[\"channel\", \"freq\"],\n",
    "        value_vars=conditions,\n",
    "        var_name=\"condition\",\n",
    "        value_name=\"power\"\n",
    "        )\n",
    "\n",
    "    for ax, group in zip(axes, groups):\n",
    "        psd_df = (power_ds.sel(subject=df[df.group == group].index)\n",
    "                        .mean([\"subject\"])\n",
    "                        .to_dataframe()\n",
    "                        )\n",
    "        psd_df = psd_df.reset_index().melt(**melt_kwargs)\n",
    "\n",
    "        psd_df[\"power\"] = np.log10(psd_df[\"power\"]) if log else psd_df[\"power\"]\n",
    "        sns.lineplot(\n",
    "            data=psd_df,\n",
    "            x=\"freq\",\n",
    "            y=\"power\",\n",
    "            units=\"channel\",\n",
    "            hue=\"condition\",\n",
    "            ax=ax,\n",
    "            errorbar=None,\n",
    "            estimator=None,\n",
    "            linewidth=.5,\n",
    "            alpha=.5\n",
    "            )\n",
    "        ax.set_title(group)\n",
    "        if vlim is not None:\n",
    "            ax.set_ylim(vlim)\n",
    "        ax.set_ylabel(\"log10(power)\")\n",
    "        ax.set_xlabel(\"Frequency (Hz)\")\n",
    "\n",
    "    fig.suptitle(\"Power Spectral Density (1-2s)\")\n",
    "    fig.show()\n",
    "\n",
    "plot_psds(power_ds, group_df=df, vlim=(-14, np.log10(2*1e-11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_power = power_ds.sum(\"freq\")\n",
    "power_ds_rel = power_ds / total_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psds(power_ds_rel, group_df=df, log=False, vlim=(0, .20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds_rel, group_df=df, band=\"delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds_rel, group_df=df, band=\"theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power_topomaps(power_ds_rel, group_df=df, band=\"alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFR for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOMPUTE = False\n",
    "\n",
    "if RECOMPUTE:\n",
    "    freqs = np.arange(2, 36)\n",
    "    kwargs = dict(\n",
    "        method=\"multitaper\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=freqs,\n",
    "        use_fft=True,\n",
    "    )\n",
    "\n",
    "    tfr_dict = defaultdict()\n",
    "    for subject, ep in tqdm(semantics_epochs.items(), total=len(semantics_epochs)):\n",
    "        print(subject)\n",
    "        this_ep = ep.copy().apply_baseline((None, 0))\n",
    "        tfr = this_ep.compute_tfr(**kwargs)\n",
    "        condition_xrs = defaultdict()\n",
    "        for condition in [\"match\", \"mismatch\"]:\n",
    "            ev = tfr[condition].average()\n",
    "            assert ev.data.shape == (len(ev.ch_names), len(ev.freqs), len(ev.times))\n",
    "            ev_xr = xr.DataArray(\n",
    "                [ev.data],\n",
    "                coords={\n",
    "                    \"subject\": [subject],\n",
    "                    \"channel\": ev.ch_names,\n",
    "                    \"time\": ev.times,\n",
    "                    \"freq\": ev.freqs,\n",
    "                },\n",
    "                dims=(\"subject\", \"channel\", \"freq\", \"time\"),\n",
    "            )\n",
    "            condition_xrs[condition] = ev_xr\n",
    "        ev_ds = xr.Dataset(condition_xrs)\n",
    "        tfr_dict[subject] = ev_ds\n",
    "    tfr_ds = xr.concat(tfr_dict.values(), dim=\"subject\")\n",
    "\n",
    "    if LAB_SERVER_IS_MOUNTED:\n",
    "        out_name = out_dir.parent / \"tfr\" / \"tfr.netcdf\"\n",
    "        tfr_ds.to_netcdf(out_name)\n",
    "\n",
    "else:\n",
    "    tfr_ds = xr.open_dataset(directory.parent / \"derivatives\" / \"tfr\" / \"tfr.netcdf\")\n",
    "\n",
    "tfr_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfr_power(tfr_ds, *, group_df, group, roi, freqs):\n",
    "    \"\"\"Get the power for a group and condition.\"\"\"\n",
    "    df = group_df\n",
    "    tfr_df = tfr_ds.sel(\n",
    "        subject=df[df.group == group].index,\n",
    "        channel=roi, freq=freqs).mean([\"freq\", \"channel\"]).to_dataframe().reset_index()\n",
    "    tfr_df = tfr_df.melt(\n",
    "        id_vars=[\"subject\", \"time\"],\n",
    "        value_vars=[\"match\", \"mismatch\"],\n",
    "        var_name=\"condition\",\n",
    "        value_name=\"power\"\n",
    "    )\n",
    "    return tfr_df\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5), constrained_layout=True)\n",
    "BAND = \"theta\"\n",
    "ylim = (0, 6*1e-9)\n",
    "\n",
    "tfr_df = get_tfr_power(tfr_ds, group_df=df, group=\"TD\", roi=ROI, freqs=freq_bands[BAND])\n",
    "sns.lineplot(data=tfr_df, x=\"time\", y=\"power\", hue=\"condition\", n_boot=100, ax=ax[0])\n",
    "ax[0].set_title(\"TD\")\n",
    "ax[0].set_ylim(ylim)\n",
    "\n",
    "tfr_df = get_tfr_power(tfr_ds, group_df=df, group=\"ASD-Verbal\", roi=ROI, freqs=freq_bands[BAND])\n",
    "sns.lineplot(data=tfr_df, x=\"time\", y=\"power\", hue=\"condition\", n_boot=100, ax=ax[1])\n",
    "ax[1].set_title(\"ASD-Verbal\")\n",
    "ax[1].set_ylim(ylim)\n",
    "\n",
    "tfr_df = get_tfr_power(tfr_ds, group_df=df, group=\"ASD-Nonverbal\", roi=ROI, freqs=freq_bands[BAND])\n",
    "sns.lineplot(data=tfr_df, x=\"time\", y=\"power\", hue=\"condition\", n_boot=100, ax=ax[2])\n",
    "ax[2].set_title(\"ASD-Nonverbal\")\n",
    "ax[2].set_ylim(ylim)\n",
    "\n",
    "fig.suptitle(f\"{BAND} power\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_to_df(xr, subject, channels=(\"Cz\", \"Fz\")):\n",
    "    \"\"\"Convert an xarray Dataset to a DataFrame.\"\"\"\n",
    "    arr = xr.sel(subject=subject, channel=list(channels))\n",
    "    if len(channels) > 1:\n",
    "        arr = arr.mean(\"channel\")\n",
    "    df = arr.to_dataframe().reset_index()\n",
    "    df = df.drop(columns=\"subject\")\n",
    "    df = df.melt(\n",
    "        id_vars=[\"time\", \"freq\"],\n",
    "        value_vars=[\"match\", \"mismatch\"],\n",
    "        var_name=\"condition\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "    df = add_band_col(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "if LAB_SERVER_IS_MOUNTED:\n",
    "    df_dict = defaultdict()\n",
    "    for subject in tqdm(tfr_ds.subject.values, total=len(tfr_ds.subject)):\n",
    "        df = xr_to_df(tfr_ds, subject)\n",
    "        out_name = out_dir.parent / \"tfr\" / \"csv\" / f\"{subject}_tfr.csv\"\n",
    "        df.to_csv(out_name, index=False)\n",
    "        df_dict[subject] = df\n",
    "    df_dict = dict(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = get_group_assignment()\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = [\"Cz\", \"Fz\"]\n",
    "\n",
    "\n",
    "group_ds_tfr = defaultdict()\n",
    "for group in [\"ASD-Nonverbal\", \"ASD-Verbal\", \"TD\"]:\n",
    "    group_ids = group_df[group_df[\"group\"] == group].index\n",
    "    group_ds = tfr_ds.sel(subject=group_ids, channel=ROI).mean(\"channel\")\n",
    "    match = group_ds[\"match\"]\n",
    "    mismatch = group_ds[\"mismatch\"]\n",
    "    diff = (mismatch - match).mean(\"subject\")\n",
    "    group_ds_tfr[group] = diff\n",
    "group_ds_tfr = xr.Dataset(dict(group_ds_tfr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_verbal = group_ds_tfr[\"ASD-Verbal\"].to_dataframe().reset_index()\n",
    "add_band_col(asd_verbal)\n",
    "asd_verbal = asd_verbal.rename(columns={\"ASD-Verbal\": \"ERDS\"})\n",
    "asd_verbal[\"group\"] = \"ASD-Verbal\"\n",
    "\n",
    "asd_nv = group_ds_tfr[\"ASD-Nonverbal\"].to_dataframe().reset_index()\n",
    "add_band_col(asd_nv)\n",
    "asd_nv = asd_nv.rename(columns={\"ASD-Nonverbal\": \"ERDS\"})\n",
    "asd_nv[\"group\"] = \"ASD-Nonverbal\"\n",
    "\n",
    "td = group_ds_tfr[\"TD\"].to_dataframe().reset_index()\n",
    "add_band_col(td)\n",
    "td = td.rename(columns={\"TD\": \"ERDS\"})\n",
    "td[\"group\"] = \"TD\"\n",
    "\n",
    "df = pd.concat([asd_verbal, asd_nv, td], ignore_index=True)\n",
    "\n",
    "g = sns.FacetGrid(df, col=\"band\", col_wrap=3, sharey=False, margin_titles=True)\n",
    "g.map(sns.lineplot, \"time\", \"ERDS\", \"group\")\n",
    "g.set_axis_labels(\"Time (s)\", \"ERDS\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.add_legend()\n",
    "g.fig.subplots_adjust(top=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvs = group_df[group_df.group == \"ASD-Nonverbal\"].index\n",
    "asds = group_df[group_df.group == \"ASD-Verbal\"].index\n",
    "tds = group_df[group_df.group == \"TD\"].index\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, constrained_layout=True, figsize=(15, 5))\n",
    "\n",
    "\n",
    "for group, this_ax in zip([\"ASD-Nonverbal\", \"ASD-Verbal\", \"TD\"], ax.flatten()):\n",
    "    subs = {\"ASD-Nonverbal\": mvs, \"ASD-Verbal\": asds, \"TD\": tds}\n",
    "    (tfr_ds[\"match\"].sel(subject=subs[group], channel=ROI, freq=slice(2,15))\n",
    "                    .mean(\"channel\")\n",
    "                    .mean(\"subject\")\n",
    "                    .plot(ax=this_ax, vmin=0, vmax=1.2e-8)\n",
    "                    )\n",
    "    this_ax.set_title(group)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Field Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_power = defaultdict()\n",
    "\n",
    "for subject, epochs in tqdm(semantics_epochs.items()):\n",
    "    gfp = epochs.copy().apply_baseline((None, 0))\n",
    "\n",
    "    band_gfps = defaultdict()\n",
    "    for band, frequencies in freq_bands.items():\n",
    "        fmin = frequencies.start\n",
    "        fmax = frequencies.stop\n",
    "        gfp = gfp.filter(fmin, fmax, l_trans_bandwidth=1, h_trans_bandwidth=1)\n",
    "        condition_gfps = defaultdict()\n",
    "        for condition in [\"match\", \"mismatch\"]:\n",
    "            this_gfp = gfp[condition].subtract_evoked()\n",
    "            this_gfp = gfp[condition].apply_hilbert(envelope=True)\n",
    "            this_gfp = gfp[condition].average()\n",
    "            assert this_gfp.data.shape == (len(this_gfp.ch_names), len(this_gfp.times))\n",
    "\n",
    "            this_gfp_xr = xr.DataArray(\n",
    "                [[this_gfp.data]],\n",
    "                coords={\n",
    "                    \"subject\": [subject],\n",
    "                    \"band\": [band],\n",
    "                    \"channel\": this_gfp.ch_names,\n",
    "                    \"time\": this_gfp.times,\n",
    "                },\n",
    "                dims=(\"subject\", \"band\", \"channel\", \"time\"),\n",
    "            )\n",
    "            condition_gfps[condition] = this_gfp_xr\n",
    "        gfp_ds = xr.Dataset(condition_gfps)\n",
    "        band_gfps[band] = gfp_ds\n",
    "    global_power[subject] = xr.concat(band_gfps.values(), dim=\"band\")\n",
    "global_power = dict(global_power)\n",
    "global_power = xr.concat(global_power.values(), dim=\"subject\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_power"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
